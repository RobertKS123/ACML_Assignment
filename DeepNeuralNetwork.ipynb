{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, classification_report, roc_auc_score, roc_curve, auc\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1     2   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1     2   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1     4    181.00  C1305486145          181.0            0.00   \n",
       "3     1     1    181.00   C840083671          181.0            0.00   \n",
       "4     1     2  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Data/onlinefraud.csv')\n",
    "# Convert the 'type' attribute to a numerical one\n",
    "data[\"type\"] = data[\"type\"].map({\"CASH_OUT\": 1, \"PAYMENT\": 2, \"CASH_IN\": 3, \"TRANSFER\": 4, \"DEBIT\": 5})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"nameOrig\", \"nameDest\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes - X: (5090096, 8) y: (5090096,)\n",
      "Test set shapes - X: (636262, 8) y: (636262,)\n",
      "Validation set shapes - X: (636262, 8) y: (636262,)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data randomly\n",
    "data = data.sample(frac=1, random_state=42)\n",
    "\n",
    "# Set the target variable (y) and input features (X)\n",
    "target_variable = 'isFraud'\n",
    "input_features = [col for col in data.columns if col != target_variable]\n",
    "\n",
    "# Determine the proportions for train, test, and validation sets\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "validation_ratio = 0.1\n",
    "\n",
    "# Split the data into train, test, and validation sets\n",
    "train_data, remaining_data = train_test_split(data, test_size=1 - train_ratio, random_state=42)\n",
    "test_data, validation_data = train_test_split(remaining_data, test_size=validation_ratio / (test_ratio + validation_ratio), random_state=42)\n",
    "\n",
    "# Set the y and X values for train, test, and validation sets\n",
    "y_train = train_data[target_variable]\n",
    "X_train = train_data[input_features]\n",
    "\n",
    "y_test = test_data[target_variable]\n",
    "X_test = test_data[input_features]\n",
    "\n",
    "y_validation = validation_data[target_variable]\n",
    "X_validation = validation_data[input_features]\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "\n",
    "# Verify the shapes of the resulting sets\n",
    "print(\"Train set shapes - X:\", X_train_scaled.shape, \"y:\", y_train.shape)\n",
    "print(\"Test set shapes - X:\", X_test_scaled.shape, \"y:\", y_test.shape)\n",
    "print(\"Validation set shapes - X:\", X_validation_scaled.shape, \"y:\", y_validation.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a DNN and return the metrics\n",
    "def train_dnn(X_train, y_train, X_val, y_val, X_test, y_test, epochs, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['Precision','Recall'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Make predictions on validation data\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred = np.round(y_val_pred)\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred = np.round(y_test_pred)\n",
    "\n",
    "    # Calculate metrics for validation data\n",
    "    val_cm = confusion_matrix(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Calculate metrics for test data\n",
    "    test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    weight_matrix = model.get_weights()\n",
    "\n",
    "    return (val_cm, val_f1, val_precision, val_recall, val_accuracy,\n",
    "            test_cm, test_f1, test_precision, test_recall, test_accuracy,\n",
    "            loss, weight_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A. Testing to find the best number of epochs on normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159066/159066 [==============================] - 164s 1ms/step - loss: 0.0050 - precision: 0.8544 - recall: 0.4768 - val_loss: 0.0050 - val_precision: 0.9836 - val_recall: 0.5030\n",
      "19884/19884 [==============================] - 12s 600us/step\n",
      "19884/19884 [==============================] - 10s 524us/step\n",
      "Epoch 1/2\n",
      "159066/159066 [==============================] - 167s 1ms/step - loss: 0.0061 - precision: 0.8008 - recall: 0.4636 - val_loss: 0.0044 - val_precision: 0.9380 - val_recall: 0.5450\n",
      "Epoch 2/2\n",
      "159066/159066 [==============================] - 162s 1ms/step - loss: 0.0044 - precision: 0.8874 - recall: 0.5606 - val_loss: 0.0057 - val_precision: 0.9968 - val_recall: 0.3733\n",
      "19884/19884 [==============================] - 12s 608us/step\n",
      "19884/19884 [==============================] - 11s 529us/step\n",
      "Epoch 1/5\n",
      "159066/159066 [==============================] - 167s 1ms/step - loss: 0.0052 - precision: 0.8012 - recall: 0.4697 - val_loss: 0.0042 - val_precision: 0.9527 - val_recall: 0.5078\n",
      "Epoch 2/5\n",
      "159066/159066 [==============================] - 160s 1ms/step - loss: 0.0064 - precision: 0.8808 - recall: 0.5558 - val_loss: 0.0055 - val_precision: 0.9968 - val_recall: 0.3745\n",
      "Epoch 3/5\n",
      "159066/159066 [==============================] - 149s 938us/step - loss: 0.0050 - precision: 0.8884 - recall: 0.5552 - val_loss: 0.0083 - val_precision: 0.9970 - val_recall: 0.3938\n",
      "Epoch 4/5\n",
      "159066/159066 [==============================] - 143s 898us/step - loss: 0.0058 - precision: 0.8809 - recall: 0.5633 - val_loss: 0.0064 - val_precision: 0.9971 - val_recall: 0.4106\n",
      "Epoch 5/5\n",
      "159066/159066 [==============================] - 143s 898us/step - loss: 0.0433 - precision: 0.8376 - recall: 0.5284 - val_loss: 0.0156 - val_precision: 0.9967 - val_recall: 0.3637\n",
      "19884/19884 [==============================] - 10s 488us/step\n",
      "19884/19884 [==============================] - 10s 520us/step\n",
      "Epoch 1/8\n",
      "159066/159066 [==============================] - 145s 905us/step - loss: 0.0049 - precision: 0.8320 - recall: 0.4763 - val_loss: 0.0041 - val_precision: 0.9925 - val_recall: 0.4754\n",
      "Epoch 2/8\n",
      "159066/159066 [==============================] - 145s 910us/step - loss: 0.0038 - precision: 0.8933 - recall: 0.5571 - val_loss: 0.0060 - val_precision: 0.9969 - val_recall: 0.3842\n",
      "Epoch 3/8\n",
      "159066/159066 [==============================] - 146s 915us/step - loss: 0.0071 - precision: 0.8891 - recall: 0.5580 - val_loss: 0.0049 - val_precision: 0.9969 - val_recall: 0.3842\n",
      "Epoch 4/8\n",
      "159066/159066 [==============================] - 145s 912us/step - loss: 0.0048 - precision: 0.8824 - recall: 0.5658 - val_loss: 0.0051 - val_precision: 0.9965 - val_recall: 0.3373\n",
      "Epoch 5/8\n",
      "159066/159066 [==============================] - 144s 907us/step - loss: 0.0061 - precision: 0.8642 - recall: 0.5616 - val_loss: 0.0056 - val_precision: 0.9932 - val_recall: 0.3517\n",
      "Epoch 6/8\n",
      "159066/159066 [==============================] - 144s 905us/step - loss: 0.0113 - precision: 0.8301 - recall: 0.5627 - val_loss: 0.0054 - val_precision: 0.9965 - val_recall: 0.3385\n",
      "Epoch 7/8\n",
      "159066/159066 [==============================] - 144s 903us/step - loss: 0.0065 - precision: 0.8747 - recall: 0.5595 - val_loss: 0.0090 - val_precision: 0.9966 - val_recall: 0.3481\n",
      "Epoch 8/8\n",
      "159066/159066 [==============================] - 145s 912us/step - loss: 0.0076 - precision: 0.8678 - recall: 0.5655 - val_loss: 0.0054 - val_precision: 0.9939 - val_recall: 0.3914\n",
      "19884/19884 [==============================] - 11s 536us/step\n",
      "19884/19884 [==============================] - 10s 507us/step\n",
      "Epoch 1/10\n",
      "159066/159066 [==============================] - 151s 944us/step - loss: 0.0055 - precision: 0.8304 - recall: 0.4553 - val_loss: 0.0048 - val_precision: 0.9906 - val_recall: 0.3782\n",
      "Epoch 2/10\n",
      "159066/159066 [==============================] - 147s 927us/step - loss: 0.0044 - precision: 0.8985 - recall: 0.5378 - val_loss: 0.0062 - val_precision: 1.0000 - val_recall: 0.2437\n",
      "Epoch 3/10\n",
      "159066/159066 [==============================] - 147s 925us/step - loss: 0.0069 - precision: 0.8968 - recall: 0.5369 - val_loss: 0.0069 - val_precision: 0.9962 - val_recall: 0.3109\n",
      "Epoch 4/10\n",
      "159066/159066 [==============================] - 147s 927us/step - loss: 0.0055 - precision: 0.9012 - recall: 0.5456 - val_loss: 0.0089 - val_precision: 0.9970 - val_recall: 0.4010\n",
      "Epoch 5/10\n",
      "159066/159066 [==============================] - 147s 923us/step - loss: 0.0069 - precision: 0.9013 - recall: 0.5447 - val_loss: 0.0069 - val_precision: 0.9943 - val_recall: 0.4154\n",
      "Epoch 6/10\n",
      "159066/159066 [==============================] - 147s 925us/step - loss: 0.0127 - precision: 0.8359 - recall: 0.5375 - val_loss: 0.0061 - val_precision: 0.9965 - val_recall: 0.3421\n",
      "Epoch 7/10\n",
      "159066/159066 [==============================] - 146s 920us/step - loss: 0.0048 - precision: 0.9008 - recall: 0.5515 - val_loss: 0.0098 - val_precision: 0.9970 - val_recall: 0.4034\n",
      "Epoch 8/10\n",
      "159066/159066 [==============================] - 148s 931us/step - loss: 0.0123 - precision: 0.8393 - recall: 0.5376 - val_loss: 0.0049 - val_precision: 0.9964 - val_recall: 0.3337\n",
      "Epoch 9/10\n",
      "159066/159066 [==============================] - 146s 920us/step - loss: 0.0061 - precision: 0.8814 - recall: 0.5249 - val_loss: 0.0086 - val_precision: 0.9894 - val_recall: 0.4490\n",
      "Epoch 10/10\n",
      "159066/159066 [==============================] - 147s 923us/step - loss: 0.0055 - precision: 0.8802 - recall: 0.5416 - val_loss: 0.0103 - val_precision: 0.9957 - val_recall: 0.2785\n",
      "19884/19884 [==============================] - 12s 582us/step\n",
      "19884/19884 [==============================] - 10s 512us/step\n",
      "Metrics for 1 epochs:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635422      7]\n",
      " [   414    419]]\n",
      "F1-score: 0.6656076250992852\n",
      "Precision: 0.9835680751173709\n",
      "Recall: 0.503001200480192\n",
      "Accuracy: 0.9993383228921419\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635415      5]\n",
      " [   445    397]]\n",
      "F1-score: 0.6382636655948553\n",
      "Precision: 0.9875621890547264\n",
      "Recall: 0.47149643705463185\n",
      "Accuracy: 0.9992927441839997\n",
      "\n",
      "Metrics for 2 epochs:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635428      1]\n",
      " [   522    311]]\n",
      "F1-score: 0.5432314410480349\n",
      "Precision: 0.9967948717948718\n",
      "Recall: 0.37334933973589435\n",
      "Accuracy: 0.9991780115738486\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635420      0]\n",
      " [   542    300]]\n",
      "F1-score: 0.5253940455341506\n",
      "Precision: 1.0\n",
      "Recall: 0.35629453681710216\n",
      "Accuracy: 0.9991481496616174\n",
      "\n",
      "Metrics for 5 epochs:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635428      1]\n",
      " [   530    303]]\n",
      "F1-score: 0.5329815303430079\n",
      "Precision: 0.9967105263157895\n",
      "Recall: 0.3637454981992797\n",
      "Accuracy: 0.9991654381371197\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635420      0]\n",
      " [   550    292]]\n",
      "F1-score: 0.5149911816578483\n",
      "Precision: 1.0\n",
      "Recall: 0.34679334916864607\n",
      "Accuracy: 0.9991355762248885\n",
      "\n",
      "Metrics for 8 epochs:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635427      2]\n",
      " [   507    326]]\n",
      "F1-score: 0.5615848406546081\n",
      "Precision: 0.9939024390243902\n",
      "Recall: 0.39135654261704683\n",
      "Accuracy: 0.9992000150881241\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635417      3]\n",
      " [   526    316]]\n",
      "F1-score: 0.5443583118001721\n",
      "Precision: 0.9905956112852664\n",
      "Recall: 0.3752969121140142\n",
      "Accuracy: 0.9991685814963018\n",
      "\n",
      "Metrics for 10 epochs:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635428      1]\n",
      " [   601    232]]\n",
      "F1-score: 0.43527204502814254\n",
      "Precision: 0.9957081545064378\n",
      "Recall: 0.2785114045618247\n",
      "Accuracy: 0.9990538488861507\n",
      "\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635420      0]\n",
      " [   608    234]]\n",
      "F1-score: 0.43494423791821557\n",
      "Precision: 1.0\n",
      "Recall: 0.27790973871733965\n",
      "Accuracy: 0.999044418808604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify hyperparameters\n",
    "epochs = [1,2,5,8,10]  # Number of epochs to train\n",
    "\n",
    "batch_size = 32  # Batch size for training\n",
    "\n",
    "# Initialize variables to store results\n",
    "loss_per_epoch = []\n",
    "val_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "# Iterate over different numbers of hidden layers\n",
    "for epoch in epochs:\n",
    "    # Train the DNN and obtain metrics\n",
    "    val_cm, val_f1, val_precision, val_recall, val_accuracy, \\\n",
    "    test_cm, test_f1, test_precision, test_recall, test_accuracy, \\\n",
    "    loss, weight_matrix = train_dnn(X_train_scaled, y_train, X_validation_scaled, y_validation, X_test_scaled, y_test, epoch, batch_size)\n",
    "    # Store the loss per epoch\n",
    "    loss_per_epoch.append(loss)\n",
    "\n",
    "    # Store the metrics\n",
    "    val_metrics.append((val_cm, val_f1, val_precision, val_recall, val_accuracy))\n",
    "    test_metrics.append((test_cm, test_f1, test_precision, test_recall, test_accuracy))\n",
    "\n",
    "# Print and plot the metrics\n",
    "for i, epoch in enumerate(epochs):\n",
    "    print(f\"Metrics for {epoch} epochs:\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    val_cm, val_f1, val_precision, val_recall, val_accuracy = val_metrics[i]\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(val_cm)\n",
    "    print(\"F1-score:\", val_f1)\n",
    "    print(\"Precision:\", val_precision)\n",
    "    print(\"Recall:\", val_recall)\n",
    "    print(\"Accuracy:\", val_accuracy)\n",
    "    print()\n",
    "\n",
    "    print(\"Test Metrics:\")\n",
    "    test_cm, test_f1, test_precision, test_recall, test_accuracy = test_metrics[i]\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(test_cm)\n",
    "    print(\"F1-score:\", test_f1)\n",
    "    print(\"Precision:\", test_precision)\n",
    "    print(\"Recall:\", test_recall)\n",
    "    print(\"Accuracy:\", test_accuracy)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of the above data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the normal set of data, applying more epochs increased the precision and decreased the recall value. We think this may be due to the number of actual fraudulent in the set being too low and the model being trained to better identify \"not fraud\" than \"fraud\".  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B. Model using the most epoch with different sampling ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "166805/166805 [==============================] - 173s 1ms/step - loss: 0.0351 - precision: 0.9299 - recall: 0.8004 - val_loss: 0.0050 - val_precision: 0.5452 - val_recall: 0.7599\n",
      "Epoch 2/10\n",
      "166805/166805 [==============================] - 162s 973us/step - loss: 0.0254 - precision: 0.9326 - recall: 0.8591 - val_loss: 0.0054 - val_precision: 0.5341 - val_recall: 0.8091\n",
      "Epoch 3/10\n",
      "166805/166805 [==============================] - 160s 959us/step - loss: 0.0228 - precision: 0.9339 - recall: 0.8755 - val_loss: 0.0062 - val_precision: 0.3876 - val_recall: 0.8715\n",
      "Epoch 4/10\n",
      "166805/166805 [==============================] - 158s 945us/step - loss: 0.0212 - precision: 0.9350 - recall: 0.8886 - val_loss: 0.0064 - val_precision: 0.3327 - val_recall: 0.8836\n",
      "Epoch 5/10\n",
      "166805/166805 [==============================] - 160s 960us/step - loss: 0.0201 - precision: 0.9363 - recall: 0.8974 - val_loss: 0.0095 - val_precision: 0.2715 - val_recall: 0.9400\n",
      "Epoch 6/10\n",
      "166805/166805 [==============================] - 162s 973us/step - loss: 0.0192 - precision: 0.9371 - recall: 0.9035 - val_loss: 0.0061 - val_precision: 0.6040 - val_recall: 0.7527\n",
      "Epoch 7/10\n",
      "166805/166805 [==============================] - 162s 974us/step - loss: 0.0184 - precision: 0.9392 - recall: 0.9084 - val_loss: 0.0061 - val_precision: 0.7327 - val_recall: 0.7731\n",
      "Epoch 8/10\n",
      "166805/166805 [==============================] - 163s 976us/step - loss: 0.0183 - precision: 0.9403 - recall: 0.9113 - val_loss: 0.0048 - val_precision: 0.5389 - val_recall: 0.8812\n",
      "Epoch 9/10\n",
      "166805/166805 [==============================] - 159s 954us/step - loss: 0.0177 - precision: 0.9405 - recall: 0.9149 - val_loss: 0.0079 - val_precision: 0.6217 - val_recall: 0.8247\n",
      "Epoch 10/10\n",
      "166805/166805 [==============================] - 224s 1ms/step - loss: 0.0172 - precision: 0.9416 - recall: 0.9177 - val_loss: 0.0060 - val_precision: 0.6654 - val_recall: 0.8259\n",
      "19884/19884 [==============================] - 16s 808us/step\n",
      "19884/19884 [==============================] - 17s 876us/step\n",
      "Epoch 1/10\n",
      "174748/174748 [==============================] - 253s 1ms/step - loss: 0.0445 - precision: 0.9351 - recall: 0.8763 - val_loss: 0.0062 - val_precision: 0.5089 - val_recall: 0.8271\n",
      "Epoch 2/10\n",
      "174748/174748 [==============================] - 248s 1ms/step - loss: 0.0307 - precision: 0.9427 - recall: 0.9239 - val_loss: 0.0059 - val_precision: 0.6441 - val_recall: 0.7323\n",
      "Epoch 3/10\n",
      "174748/174748 [==============================] - 245s 1ms/step - loss: 0.0275 - precision: 0.9461 - recall: 0.9367 - val_loss: 0.0044 - val_precision: 0.8949 - val_recall: 0.7359\n",
      "Epoch 4/10\n",
      "174748/174748 [==============================] - 237s 1ms/step - loss: 0.0283 - precision: 0.9472 - recall: 0.9430 - val_loss: 0.0031 - val_precision: 0.7087 - val_recall: 0.7419\n",
      "Epoch 5/10\n",
      "174748/174748 [==============================] - 234s 1ms/step - loss: 0.0283 - precision: 0.9482 - recall: 0.9470 - val_loss: 0.0044 - val_precision: 0.6550 - val_recall: 0.7611\n",
      "Epoch 6/10\n",
      "174748/174748 [==============================] - 232s 1ms/step - loss: 0.0301 - precision: 0.9496 - recall: 0.9498 - val_loss: 0.0038 - val_precision: 0.8843 - val_recall: 0.7431\n",
      "Epoch 7/10\n",
      "174748/174748 [==============================] - 274s 2ms/step - loss: 0.0239 - precision: 0.9505 - recall: 0.9517 - val_loss: 0.0032 - val_precision: 0.8621 - val_recall: 0.7203\n",
      "Epoch 8/10\n",
      "174748/174748 [==============================] - 243s 1ms/step - loss: 0.0229 - precision: 0.9512 - recall: 0.9545 - val_loss: 0.0043 - val_precision: 0.9322 - val_recall: 0.7431\n",
      "Epoch 9/10\n",
      "174748/174748 [==============================] - 240s 1ms/step - loss: 0.0235 - precision: 0.9519 - recall: 0.9573 - val_loss: 0.0044 - val_precision: 0.9237 - val_recall: 0.7119\n",
      "Epoch 10/10\n",
      "174748/174748 [==============================] - 214s 1ms/step - loss: 0.0225 - precision: 0.9524 - recall: 0.9590 - val_loss: 0.0031 - val_precision: 0.8209 - val_recall: 0.7539\n",
      "19884/19884 [==============================] - 12s 585us/step\n",
      "19884/19884 [==============================] - 18s 898us/step\n",
      "Epoch 1/10\n",
      "190634/190634 [==============================] - 245s 1ms/step - loss: 0.0520 - precision: 0.9468 - recall: 0.9299 - val_loss: 0.0079 - val_precision: 0.4533 - val_recall: 0.8571\n",
      "Epoch 2/10\n",
      "190634/190634 [==============================] - 259s 1ms/step - loss: 0.0381 - precision: 0.9542 - recall: 0.9597 - val_loss: 0.0061 - val_precision: 0.4309 - val_recall: 0.7827\n",
      "Epoch 3/10\n",
      "190634/190634 [==============================] - 253s 1ms/step - loss: 0.0353 - precision: 0.9578 - recall: 0.9649 - val_loss: 0.0040 - val_precision: 0.7804 - val_recall: 0.7851\n",
      "Epoch 4/10\n",
      "190634/190634 [==============================] - 237s 1ms/step - loss: 0.0335 - precision: 0.9606 - recall: 0.9694 - val_loss: 0.0048 - val_precision: 0.7707 - val_recall: 0.7827\n",
      "Epoch 5/10\n",
      "190634/190634 [==============================] - 237s 1ms/step - loss: 0.0318 - precision: 0.9624 - recall: 0.9715 - val_loss: 0.0040 - val_precision: 0.9165 - val_recall: 0.6723\n",
      "Epoch 6/10\n",
      "190634/190634 [==============================] - 245s 1ms/step - loss: 0.0321 - precision: 0.9641 - recall: 0.9738 - val_loss: 0.0039 - val_precision: 0.7835 - val_recall: 0.7863\n",
      "Epoch 7/10\n",
      "190634/190634 [==============================] - 254s 1ms/step - loss: 0.0298 - precision: 0.9656 - recall: 0.9757 - val_loss: 0.0059 - val_precision: 0.7380 - val_recall: 0.7575\n",
      "Epoch 8/10\n",
      "190634/190634 [==============================] - 255s 1ms/step - loss: 0.0278 - precision: 0.9663 - recall: 0.9767 - val_loss: 0.0047 - val_precision: 0.8874 - val_recall: 0.7191\n",
      "Epoch 9/10\n",
      "190634/190634 [==============================] - 292s 2ms/step - loss: 0.0302 - precision: 0.9665 - recall: 0.9770 - val_loss: 0.0038 - val_precision: 0.8732 - val_recall: 0.7275\n",
      "Epoch 10/10\n",
      "190634/190634 [==============================] - 255s 1ms/step - loss: 0.0288 - precision: 0.9672 - recall: 0.9767 - val_loss: 0.0042 - val_precision: 0.7099 - val_recall: 0.7695\n",
      "19884/19884 [==============================] - 15s 765us/step\n",
      "19884/19884 [==============================] - 16s 796us/step\n",
      "Epoch 1/10\n",
      "206520/206520 [==============================] - 275s 1ms/step - loss: 0.0544 - precision: 0.9509 - recall: 0.9571 - val_loss: 0.0311 - val_precision: 0.0710 - val_recall: 0.9808\n",
      "Epoch 2/10\n",
      "206520/206520 [==============================] - 264s 1ms/step - loss: 0.0407 - precision: 0.9595 - recall: 0.9750 - val_loss: 0.0136 - val_precision: 0.1555 - val_recall: 0.9616\n",
      "Epoch 3/10\n",
      "206520/206520 [==============================] - 247s 1ms/step - loss: 0.0373 - precision: 0.9635 - recall: 0.9789 - val_loss: 0.0062 - val_precision: 0.6543 - val_recall: 0.8451\n",
      "Epoch 4/10\n",
      "206520/206520 [==============================] - 247s 1ms/step - loss: 0.0371 - precision: 0.9661 - recall: 0.9815 - val_loss: 0.0084 - val_precision: 0.7349 - val_recall: 0.7719\n",
      "Epoch 5/10\n",
      "206520/206520 [==============================] - 249s 1ms/step - loss: 0.0338 - precision: 0.9688 - recall: 0.9829 - val_loss: 0.0045 - val_precision: 0.8198 - val_recall: 0.7539\n",
      "Epoch 6/10\n",
      "206520/206520 [==============================] - 248s 1ms/step - loss: 0.0325 - precision: 0.9707 - recall: 0.9837 - val_loss: 0.0039 - val_precision: 0.9332 - val_recall: 0.6711\n",
      "Epoch 7/10\n",
      "206520/206520 [==============================] - 248s 1ms/step - loss: 0.0319 - precision: 0.9721 - recall: 0.9845 - val_loss: 0.0058 - val_precision: 0.9179 - val_recall: 0.6447\n",
      "Epoch 8/10\n",
      "206520/206520 [==============================] - 248s 1ms/step - loss: 0.0320 - precision: 0.9728 - recall: 0.9850 - val_loss: 0.0036 - val_precision: 0.9237 - val_recall: 0.7119\n",
      "Epoch 9/10\n",
      "206520/206520 [==============================] - 245s 1ms/step - loss: 0.0317 - precision: 0.9741 - recall: 0.9853 - val_loss: 0.0045 - val_precision: 0.7509 - val_recall: 0.7887\n",
      "Epoch 10/10\n",
      "206520/206520 [==============================] - 227s 1ms/step - loss: 0.0300 - precision: 0.9746 - recall: 0.9857 - val_loss: 0.0051 - val_precision: 0.8252 - val_recall: 0.7479\n",
      "19884/19884 [==============================] - 14s 679us/step\n",
      "19884/19884 [==============================] - 12s 595us/step\n",
      "Epoch 1/10\n",
      "222406/222406 [==============================] - 232s 1ms/step - loss: 0.0599 - precision: 0.9582 - recall: 0.9587 - val_loss: 0.0143 - val_precision: 0.2564 - val_recall: 0.9292\n",
      "Epoch 2/10\n",
      "222406/222406 [==============================] - 219s 984us/step - loss: 0.0427 - precision: 0.9674 - recall: 0.9772 - val_loss: 0.0093 - val_precision: 0.4236 - val_recall: 0.8848\n",
      "Epoch 3/10\n",
      "222406/222406 [==============================] - 221s 994us/step - loss: 0.0389 - precision: 0.9711 - recall: 0.9802 - val_loss: 0.0084 - val_precision: 0.3826 - val_recall: 0.9016\n",
      "Epoch 4/10\n",
      "222406/222406 [==============================] - 216s 972us/step - loss: 0.0368 - precision: 0.9733 - recall: 0.9816 - val_loss: 0.0146 - val_precision: 0.1706 - val_recall: 0.9700\n",
      "Epoch 5/10\n",
      "222406/222406 [==============================] - 201s 906us/step - loss: 0.0352 - precision: 0.9747 - recall: 0.9824 - val_loss: 0.0138 - val_precision: 0.2228 - val_recall: 0.9472\n",
      "Epoch 6/10\n",
      "222406/222406 [==============================] - 194s 874us/step - loss: 0.0350 - precision: 0.9758 - recall: 0.9829 - val_loss: 0.0060 - val_precision: 0.5591 - val_recall: 0.8463\n",
      "Epoch 7/10\n",
      "222406/222406 [==============================] - 196s 880us/step - loss: 0.0340 - precision: 0.9770 - recall: 0.9835 - val_loss: 0.0101 - val_precision: 0.2890 - val_recall: 0.9556\n",
      "Epoch 8/10\n",
      "222406/222406 [==============================] - 194s 873us/step - loss: 0.0325 - precision: 0.9775 - recall: 0.9842 - val_loss: 0.0121 - val_precision: 0.2637 - val_recall: 0.9580\n",
      "Epoch 9/10\n",
      "222406/222406 [==============================] - 195s 878us/step - loss: 0.0325 - precision: 0.9780 - recall: 0.9844 - val_loss: 0.0181 - val_precision: 0.1627 - val_recall: 0.9520\n",
      "Epoch 10/10\n",
      "222406/222406 [==============================] - 194s 870us/step - loss: 0.0320 - precision: 0.9788 - recall: 0.9847 - val_loss: 0.0098 - val_precision: 0.4051 - val_recall: 0.9220\n",
      "19884/19884 [==============================] - 11s 542us/step\n",
      "19884/19884 [==============================] - 10s 506us/step\n",
      "Metrics for sampling ratio 0.05:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635083    346]\n",
      " [   145    688]]\n",
      "F1-score: 0.7370112479914301\n",
      "Precision: 0.6653771760154739\n",
      "Recall: 0.8259303721488596\n",
      "Accuracy: 0.9992283053207641\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635131    289]\n",
      " [   125    717]]\n",
      "F1-score: 0.775974025974026\n",
      "Precision: 0.7127236580516899\n",
      "Recall: 0.8515439429928741\n",
      "Accuracy: 0.9993493246492797\n",
      "\n",
      "Metrics for sampling ratio 0.1:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635292    137]\n",
      " [   205    628]]\n",
      "F1-score: 0.7859824780976219\n",
      "Precision: 0.8209150326797385\n",
      "Recall: 0.7539015606242497\n",
      "Accuracy: 0.9994624855798397\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635313    107]\n",
      " [   170    672]]\n",
      "F1-score: 0.8291178285009254\n",
      "Precision: 0.8626444159178434\n",
      "Recall: 0.7980997624703088\n",
      "Accuracy: 0.999564644753262\n",
      "\n",
      "Metrics for sampling ratio 0.2:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635167    262]\n",
      " [   192    641]]\n",
      "F1-score: 0.7384792626728112\n",
      "Precision: 0.7098560354374308\n",
      "Recall: 0.7695078031212484\n",
      "Accuracy: 0.9992864574656353\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635206    214]\n",
      " [   170    672]]\n",
      "F1-score: 0.7777777777777778\n",
      "Precision: 0.7584650112866818\n",
      "Recall: 0.7980997624703088\n",
      "Accuracy: 0.999396475037013\n",
      "\n",
      "Metrics for sampling ratio 0.3:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[635297    132]\n",
      " [   210    623]]\n",
      "F1-score: 0.7846347607052898\n",
      "Precision: 0.8251655629139073\n",
      "Recall: 0.7478991596638656\n",
      "Accuracy: 0.9994624855798397\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[635303    117]\n",
      " [   178    664]]\n",
      "F1-score: 0.8182378311768331\n",
      "Precision: 0.8501920614596671\n",
      "Recall: 0.7885985748218527\n",
      "Accuracy: 0.9995363545206221\n",
      "\n",
      "Metrics for sampling ratio 0.4:\n",
      "Validation Metrics:\n",
      "Confusion Matrix:\n",
      "[[634301   1128]\n",
      " [    65    768]]\n",
      "F1-score: 0.5628435324294614\n",
      "Precision: 0.4050632911392405\n",
      "Recall: 0.921968787515006\n",
      "Accuracy: 0.9981249862478035\n",
      "Test Metrics:\n",
      "Confusion Matrix:\n",
      "[[634379   1041]\n",
      " [    43    799]]\n",
      "F1-score: 0.5958240119313944\n",
      "Precision: 0.4342391304347826\n",
      "Recall: 0.9489311163895487\n",
      "Accuracy: 0.9982962993232347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Specify hyperparameters\n",
    "epochs = 10  # Number of epochs to train\n",
    "batch_size = 32  # Batch size for training\n",
    "sampling_ratios = [0.05,0.1, 0.2, 0.3, 0.4]  # Sampling ratios to test\n",
    "#,0.1, 0.2, 0.3, 0.4\n",
    "# Initialize variables to store results\n",
    "loss_per_epoch = []\n",
    "val_metrics = []\n",
    "test_metrics = []\n",
    "\n",
    "# Iterate over different sampling ratios\n",
    "for ratio in sampling_ratios:\n",
    "    # Apply SMOTE to augment the training data\n",
    "    smote = SMOTE(sampling_strategy=ratio, random_state=42)\n",
    "    X_train_aug, y_train_aug = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "    # Train the DNN and obtain metrics\n",
    "    val_cm, val_f1, val_precision, val_recall, val_accuracy, \\\n",
    "    test_cm, test_f1, test_precision, test_recall, test_accuracy, \\\n",
    "    loss, weight_matrix = train_dnn(X_train_aug, y_train_aug, X_validation_scaled, y_validation, X_test_scaled, y_test, epochs, batch_size)\n",
    "\n",
    "    # Store the loss per epoch\n",
    "    loss_per_epoch.append(loss)\n",
    "\n",
    "    # Store the metrics\n",
    "    val_metrics.append((val_cm, val_f1, val_precision, val_recall, val_accuracy))\n",
    "    test_metrics.append((test_cm, test_f1, test_precision, test_recall, test_accuracy))\n",
    "\n",
    "# Print the results\n",
    "for i, ratio in enumerate(sampling_ratios):\n",
    "    print(f\"Metrics for sampling ratio {ratio}:\")\n",
    "    print(\"Validation Metrics:\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(val_metrics[i][0])\n",
    "    print(\"F1-score:\", val_metrics[i][1])\n",
    "    print(\"Precision:\", val_metrics[i][2])\n",
    "    print(\"Recall:\", val_metrics[i][3])\n",
    "    print(\"Accuracy:\", val_metrics[i][4])\n",
    "\n",
    "    print(\"Test Metrics:\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(test_metrics[i][0])\n",
    "    print(\"F1-score:\", test_metrics[i][1])\n",
    "    print(\"Precision:\", test_metrics[i][2])\n",
    "    print(\"Recall:\", test_metrics[i][3])\n",
    "    print(\"Accuracy:\", test_metrics[i][4])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of the above data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the redistribution of data increases the recall value but also decreases the precision value. We think 0.1 is the best ratio to use for resampling the data because the recall rate was close to 80% on the test data but also had an 86% on the precision. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
